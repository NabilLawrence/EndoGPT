{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7478116d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-14T14:37:57.572791Z",
     "start_time": "2023-03-14T14:37:57.561518Z"
    }
   },
   "source": [
    "---\n",
    "## Model  \n",
    "---\n",
    "### Content\n",
    "---\n",
    "\n",
    "- **[Libraries to use](#Libraries_to_use)**\n",
    "\n",
    "- **[Loading the dataset](#Loading_dataset)**\n",
    "\n",
    "- **[Load tokenizer and model](#tokenizer_model)**\n",
    "\n",
    "- **[Load tokenizer and model](#tokenizer_model)**\n",
    "\n",
    "- **[Tokenize the datasets](#tokenize)**\n",
    "\n",
    "- **[Creating a dictionary with train, test, validation datasets](#train_test_validation)**\n",
    "\n",
    "- **[Training model](#Training_model)**\n",
    "\n",
    " ---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f43834c5",
   "metadata": {},
   "source": [
    "<a id=\"Libraries_to_use\"> </a>\n",
    "\n",
    "---\n",
    "### Libraries to use \n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81204670",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-14T16:08:38.273709Z",
     "start_time": "2023-03-14T16:08:28.976880Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "os.environ['WANDB_DISABLED'] = 'true'\n",
    "#--------------------------------------------------------\n",
    "import datasets\n",
    "from datasets import Dataset\n",
    "import torch\n",
    "torch.cuda.is_available()\n",
    "#--------------------------------------------------------\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModelForCausalLM\n",
    "from transformers import Trainer, TrainingArguments\n",
    "#--------------------------------------------------------\n",
    "from endogpt.Preprocessor import preprocess_real\n",
    "from endogpt.Preprocessor import preprocess_synthetic\n",
    "from endogpt.Classifier import train_test_validation "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe32a5f8",
   "metadata": {},
   "source": [
    "<a id=\"Loading_dataset\"> </a>\n",
    "\n",
    "---\n",
    "### Loading the dataset \n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d5a9a3f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-14T16:08:47.758246Z",
     "start_time": "2023-03-14T16:08:40.946960Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>General Practitioner</th>\n",
       "      <th>Endoscopist</th>\n",
       "      <th>Instrument</th>\n",
       "      <th>Extent of Exam</th>\n",
       "      <th>Indications</th>\n",
       "      <th>findings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dr. Taylor</td>\n",
       "      <td>Dr. el-Hasen</td>\n",
       "      <td>FG2</td>\n",
       "      <td>D1</td>\n",
       "      <td>Ongoing reflux symptoms.</td>\n",
       "      <td>Columnar lined oesophagus is present. The segm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dr. Cheek</td>\n",
       "      <td>Dr. el-Hasen</td>\n",
       "      <td>FG4</td>\n",
       "      <td>Oesophagus</td>\n",
       "      <td>Endoscopic ultrasound findings</td>\n",
       "      <td>There is an ulcer in the stomach which is supe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dr. al-Zamani</td>\n",
       "      <td>Dr. Hall</td>\n",
       "      <td>FG7</td>\n",
       "      <td>D1</td>\n",
       "      <td>Nausea and/or Vomiting Haematemesis or Melaen...</td>\n",
       "      <td>LA Grade  D oesophagitis. The oesopahgitis is ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dr. el-Hussein</td>\n",
       "      <td>Dr. Lee</td>\n",
       "      <td>FG7</td>\n",
       "      <td>D2</td>\n",
       "      <td>IDA</td>\n",
       "      <td>There is a polyp in the body which is sessile ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dr. Hendricks</td>\n",
       "      <td>Dr. Lee</td>\n",
       "      <td>FG3</td>\n",
       "      <td>Pylorus</td>\n",
       "      <td>Dysphagia/Odynophagia .</td>\n",
       "      <td>There is a stricture in the fundus which is Oe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>Dr. Salvador-Rojas</td>\n",
       "      <td>Dr. Nguyen</td>\n",
       "      <td>FG1</td>\n",
       "      <td>Failed intubation</td>\n",
       "      <td>CD</td>\n",
       "      <td>There is a polyp in the oesophagus at 22 cm wh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>Dr. el-Haq</td>\n",
       "      <td>Dr. Burns</td>\n",
       "      <td>FG7</td>\n",
       "      <td>Oesophagus</td>\n",
       "      <td>Other - chronic cough ?GORD</td>\n",
       "      <td>There is a nodule in the oesophagus at 39 cm w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>Dr. Hassan</td>\n",
       "      <td>Dr. Nguyen</td>\n",
       "      <td>FG2</td>\n",
       "      <td>Stomach body</td>\n",
       "      <td>Other- liver abscesses</td>\n",
       "      <td>Normal gastroscopy to the duodenum.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>Dr. Murray</td>\n",
       "      <td>Dr. el-Hasen</td>\n",
       "      <td>FG2</td>\n",
       "      <td>Pylorus</td>\n",
       "      <td>Weight Loss Nausea and/or Vomiting Other- Ear...</td>\n",
       "      <td>Normal gastroscopy to the duodenum.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>Dr. Mendez</td>\n",
       "      <td>Dr. Edwards</td>\n",
       "      <td>FG2</td>\n",
       "      <td>D2</td>\n",
       "      <td>Eosinophilic oesophatitis assessment</td>\n",
       "      <td>There is a nodule in the body which is stalked...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      General Practitioner    Endoscopist Instrument         Extent of Exam  \\\n",
       "0               Dr. Taylor   Dr. el-Hasen      FG2                     D1     \n",
       "1                Dr. Cheek   Dr. el-Hasen      FG4             Oesophagus     \n",
       "2            Dr. al-Zamani       Dr. Hall      FG7                     D1     \n",
       "3           Dr. el-Hussein        Dr. Lee      FG7                     D2     \n",
       "4            Dr. Hendricks        Dr. Lee      FG3                Pylorus     \n",
       "...                    ...            ...        ...                    ...   \n",
       "49995   Dr. Salvador-Rojas     Dr. Nguyen      FG1      Failed intubation     \n",
       "49996           Dr. el-Haq      Dr. Burns      FG7             Oesophagus     \n",
       "49997           Dr. Hassan     Dr. Nguyen      FG2           Stomach body     \n",
       "49998           Dr. Murray   Dr. el-Hasen      FG2                Pylorus     \n",
       "49999           Dr. Mendez    Dr. Edwards      FG2                     D2     \n",
       "\n",
       "                                             Indications  \\\n",
       "0                              Ongoing reflux symptoms.    \n",
       "1                         Endoscopic ultrasound findings   \n",
       "2       Nausea and/or Vomiting Haematemesis or Melaen...   \n",
       "3                                                   IDA    \n",
       "4                               Dysphagia/Odynophagia .    \n",
       "...                                                  ...   \n",
       "49995                                                CD    \n",
       "49996                       Other - chronic cough ?GORD    \n",
       "49997                            Other- liver abscesses    \n",
       "49998   Weight Loss Nausea and/or Vomiting Other- Ear...   \n",
       "49999              Eosinophilic oesophatitis assessment    \n",
       "\n",
       "                                                findings  \n",
       "0      Columnar lined oesophagus is present. The segm...  \n",
       "1      There is an ulcer in the stomach which is supe...  \n",
       "2      LA Grade  D oesophagitis. The oesopahgitis is ...  \n",
       "3      There is a polyp in the body which is sessile ...  \n",
       "4      There is a stricture in the fundus which is Oe...  \n",
       "...                                                  ...  \n",
       "49995  There is a polyp in the oesophagus at 22 cm wh...  \n",
       "49996  There is a nodule in the oesophagus at 39 cm w...  \n",
       "49997               Normal gastroscopy to the duodenum.   \n",
       "49998               Normal gastroscopy to the duodenum.   \n",
       "49999  There is a nodule in the body which is stalked...  \n",
       "\n",
       "[50000 rows x 6 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string = pd.read_csv('data/real.csv')\n",
    "real = preprocess_real(string)\n",
    "real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4cd63c49",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-14T16:08:48.621102Z",
     "start_time": "2023-03-14T16:08:48.500557Z"
    }
   },
   "outputs": [],
   "source": [
    "real[\"text\"] = real['General Practitioner'] + real['Endoscopist'] + real['Instrument'] + 'INDICATIONS FOR PROCEDURE:' + real['Indications'] + 'Extent of Exam:'+ real['Extent of Exam'] +'FINDINGS: '+ real['findings']\n",
    "df = real[[\"text\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "875c17f4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-14T16:08:49.516689Z",
     "start_time": "2023-03-14T16:08:49.504644Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Dr. Taylor Dr. el-Hasen  FG2  INDICATIONS FOR PROCEDURE: Ongoing reflux symptoms. Extent of Exam:  D1  FINDINGS: Columnar lined oesophagus is present. The segment looks flat. Some areas of vascular abnormalities are seen. No abnormal pit pattern is seen. NA'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.text.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "174c02e1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-14T16:08:50.301891Z",
     "start_time": "2023-03-14T16:08:50.229796Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text'],\n",
       "    num_rows: 50000\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = Dataset.from_pandas(df)\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f336e1f1",
   "metadata": {},
   "source": [
    "<a id=\"tokenizer_model\"> </a>\n",
    "\n",
    "---\n",
    "### Load tokenizer and model \n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "22e693ce",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-14T16:08:59.228483Z",
     "start_time": "2023-03-14T16:08:51.690968Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/biogpt\", use_fast=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(\"tombrooks248/EndoGPT\")#.to('cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82342c74",
   "metadata": {},
   "source": [
    "<a id=\"tokenize\"> </a>\n",
    "\n",
    "---\n",
    "### Tokenize the datasets \n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b2f0cd5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-14T16:08:59.958859Z",
     "start_time": "2023-03-14T16:08:59.952990Z"
    }
   },
   "outputs": [],
   "source": [
    "def tokenize(batch):\n",
    "    return tokenizer(batch[\"text\"], return_tensors=\"pt\", padding=True, truncation=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8824867a",
   "metadata": {},
   "source": [
    "<a id=\"train_test_validation\"> </a>\n",
    "\n",
    "---\n",
    "### Creating a dictionary with train, test, validation datasets \n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "58f2cd4f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-14T16:09:34.739510Z",
     "start_time": "2023-03-14T16:09:02.742916Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/50000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ds = ds.map(tokenize, num_proc=4, batched=True)\n",
    "ds = ds.remove_columns([\"text\"])\n",
    "tts_ds = ds.train_test_split(test_size=0.3)\n",
    "tts_ds\n",
    "block_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7f1a464c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-14T16:10:43.773882Z",
     "start_time": "2023-03-14T16:10:43.759441Z"
    }
   },
   "outputs": [],
   "source": [
    "def group_texts(examples):\n",
    "    # Concatenate all texts.\n",
    "    concatenated_examples = {k: sum(examples[k], []) for k in examples.keys()}\n",
    "    total_length = len(concatenated_examples[list(examples.keys())[0]])\n",
    "    # We drop the small remainder, we could add padding if the model supported it instead of this drop, you can\n",
    "        # customize this part to your needs.\n",
    "    total_length = (total_length // block_size) * block_size\n",
    "    # Split by chunks of max_len.\n",
    "    result = {\n",
    "        k: [t[i : i + block_size] for i in range(0, total_length, block_size)]\n",
    "        for k, t in concatenated_examples.items()\n",
    "    }\n",
    "    result[\"labels\"] = result[\"input_ids\"].copy()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0669044c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-14T16:11:34.205423Z",
     "start_time": "2023-03-14T16:10:44.805608Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/35000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/15000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lm_datasets = tts_ds.map(\n",
    "    group_texts,\n",
    "    batched=True,\n",
    "    batch_size=1000,\n",
    "    num_proc=4,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2f156a45",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-14T16:11:35.255508Z",
     "start_time": "2023-03-14T16:11:35.197602Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'. No nodularity is present. Short segment only. The segment looks flat. NA <pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(lm_datasets[\"train\"][17][\"input_ids\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc0633cc",
   "metadata": {},
   "source": [
    "<a id=\"Training_model\"> </a>\n",
    "\n",
    "---\n",
    "### Training model \n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e1c7f686",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-14T16:11:39.144196Z",
     "start_time": "2023-03-14T16:11:39.080516Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    weight_decay=0.01,\n",
    "    output_dir=\"models\",\n",
    "    report_to=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c2a9baa8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-14T16:11:48.990567Z",
     "start_time": "2023-03-14T16:11:48.536521Z"
    }
   },
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=lm_datasets[\"train\"],\n",
    "    eval_dataset=lm_datasets[\"test\"],\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37157112",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "719c8a72",
   "metadata": {},
   "source": [
    "### Complete model training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6480cdb1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-14T16:07:03.080872Z",
     "start_time": "2023-03-14T16:07:03.058663Z"
    }
   },
   "outputs": [],
   "source": [
    "def Model(string):\n",
    "    df = pd.read_csv('data/real.csv')\n",
    "    real = preprocess_real(df)\n",
    "    real[\"text\"] = real['General Practitioner'] + real['Endoscopist'] + real['Instrument'] + 'INDICATIONS FOR PROCEDURE:' + real['Indications'] + 'Extent of Exam:'+ real['Extent of Exam'] +'FINDINGS: '+ real['findings']\n",
    "    ds = Dataset.from_pandas(df)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"microsoft/biogpt\", use_fast=True)\n",
    "    model = AutoModelForCausalLM.from_pretrained(\"tombrooks248/EndoGPT\")#.to('cuda')\n",
    "    def tokenize(batch):\n",
    "        return tokenizer(batch[\"text\"], return_tensors=\"pt\", padding=True, truncation=True)\n",
    "    ds = ds.map(tokenize, num_proc=4, batched=True)\n",
    "    ds = ds.remove_columns([\"text\"])\n",
    "    tts_ds = ds.train_test_split(test_size=0.3)\n",
    "    tts_ds\n",
    "    block_size = 64\n",
    "    def group_texts(examples):\n",
    "        # Concatenate all texts.\n",
    "        concatenated_examples = {k: sum(examples[k], []) for k in examples.keys()}\n",
    "        total_length = len(concatenated_examples[list(examples.keys())[0]])\n",
    "        # We drop the small remainder, we could add padding if the model supported it instead of this drop, you can\n",
    "            # customize this part to your needs.\n",
    "        total_length = (total_length // block_size) * block_size\n",
    "        # Split by chunks of max_len.\n",
    "        result = {\n",
    "            k: [t[i : i + block_size] for i in range(0, total_length, block_size)]\n",
    "            for k, t in concatenated_examples.items()\n",
    "        }\n",
    "        result[\"labels\"] = result[\"input_ids\"].copy()\n",
    "        return result\n",
    "    lm_datasets = tts_ds.map(\n",
    "        group_texts,\n",
    "        batched=True,\n",
    "        batch_size=1000,\n",
    "        num_proc=4,\n",
    "    )\n",
    "    tokenizer.decode(lm_datasets[\"train\"][17][\"input_ids\"])\n",
    "\n",
    "    training_args = TrainingArguments(\n",
    "        evaluation_strategy = \"epoch\",\n",
    "        learning_rate=2e-5,\n",
    "        weight_decay=0.01,\n",
    "        output_dir=\"models\",\n",
    "        report_to=None\n",
    "    )\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=lm_datasets[\"train\"],\n",
    "        eval_dataset=lm_datasets[\"test\"],\n",
    "\n",
    "    )\n",
    "    trainer.train()\n",
    "    return trainer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
